{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8b2aed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 4, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mannotation.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 2 fields in line 4, saw 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.activations import relu, sigmoid, softmax\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('annotation.txt', sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09098a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73593532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7def267d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2be97fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение завершено!\n",
      "Обучающая выборка: 8000 примеров\n",
      "Тестовая выборка: 2000 примеров\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Параметры\n",
    "images_folder = 'images'  # папка с исходными изображениями\n",
    "annotation_file = 'annotation.txt'  # файл с аннотациями\n",
    "train_ratio = 0.8  # доля обучающей выборки\n",
    "random_seed = 42  # для воспроизводимости результатов\n",
    "\n",
    "# Создаем папки для train и test\n",
    "os.makedirs('train/images', exist_ok=True)\n",
    "os.makedirs('test/images', exist_ok=True)\n",
    "\n",
    "# Читаем аннотации\n",
    "with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Парсим данные\n",
    "data = []\n",
    "for line in lines:\n",
    "    filename, label = line.strip().split(',', 1)\n",
    "    data.append((filename, label))\n",
    "\n",
    "# Разделяем данные\n",
    "train_data, test_data = train_test_split(\n",
    "    data, \n",
    "    train_size=train_ratio, \n",
    "    random_state=random_seed,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Функция для сохранения данных\n",
    "def save_dataset(data, dataset_name):\n",
    "    image_folder = f'{dataset_name}/images'\n",
    "    ann_file = f'{dataset_name}/annotation.txt'\n",
    "    \n",
    "    with open(ann_file, 'w', encoding='utf-8') as f:\n",
    "        for filename, label in data:\n",
    "            # Копируем изображение\n",
    "            src_path = os.path.join(images_folder, filename)\n",
    "            dst_path = os.path.join(image_folder, filename)\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            # Записываем аннотацию\n",
    "            f.write(f'{filename},{label}\\n')\n",
    "\n",
    "# Сохраняем обе выборки\n",
    "save_dataset(train_data, 'train')\n",
    "save_dataset(test_data, 'test')\n",
    "\n",
    "print(f'Распределение завершено!')\n",
    "print(f'Обучающая выборка: {len(train_data)} примеров')\n",
    "print(f'Тестовая выборка: {len(test_data)} примеров')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8eed35f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcudnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcudnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttrDict\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "import pandas as pd\n",
    "\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False\n",
    "\n",
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt\n",
    "\n",
    "#Запускаем обучение\n",
    "opt = get_config(\"config/custom_data_train.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6b009ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] Синтаксическая ошибка в имени файла, имени папки или метке тома",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     df.to_csv(labels_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m, header=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Обрабатываем обе выборки\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m process_dataset(test_df, test_dir)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mРазделение завершено!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mprocess_dataset\u001b[39m\u001b[34m(df, target_dir)\u001b[39m\n\u001b[32m     33\u001b[39m     src = os.path.join(images_dir, file_name)\n\u001b[32m     34\u001b[39m     dst = os.path.join(target_dir, \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m, file_name)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Сохраняем метки\u001b[39;00m\n\u001b[32m     38\u001b[39m labels_path = os.path.join(target_dir, \u001b[33m\"\u001b[39m\u001b[33mlabels.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:460\u001b[39m, in \u001b[36mcopy2\u001b[39m\u001b[34m(src, dst, follow_symlinks)\u001b[39m\n\u001b[32m    458\u001b[39m     flags |= _winapi.COPY_FILE_COPY_SYMLINK\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCopyFile2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[31mOSError\u001b[39m: [WinError 123] Синтаксическая ошибка в имени файла, имени папки или метке тома"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Конфигурация\n",
    "images_dir = \"images\"  # папка с изображениями\n",
    "labels_file = \"labels.csv\"  # файл с метками\n",
    "train_dir = \"train\"  # папка для тренировочных данных\n",
    "test_dir = \"test\"    # папка для тестовых данных\n",
    "test_size = 0.2      # доля тестовой выборки\n",
    "random_state = 42    # для воспроизводимости результатов\n",
    "\n",
    "# Создаем папки для тренировочных и тестовых данных\n",
    "os.makedirs(os.path.join(train_dir, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"images\"), exist_ok=True)\n",
    "\n",
    "# Загружаем метки\n",
    "df = pd.read_csv(labels_file, header=None, names=[\"file\", \"label\"])\n",
    "\n",
    "# Разделяем данные\n",
    "train_df, test_df = train_test_split(\n",
    "    df, \n",
    "    test_size=test_size, \n",
    "    random_state=random_state,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Функция для копирования файлов и создания меток\n",
    "def process_dataset(df, target_dir):\n",
    "    # Копируем изображения\n",
    "    for file_name in df[\"file\"]:\n",
    "        src = os.path.join(images_dir, file_name)\n",
    "        dst = os.path.join(target_dir, \"images\", file_name)\n",
    "        shutil.copy2(src, dst)\n",
    "    \n",
    "    # Сохраняем метки\n",
    "    labels_path = os.path.join(target_dir, \"labels.csv\")\n",
    "    df.to_csv(labels_path, index=False, header=False)\n",
    "\n",
    "# Обрабатываем обе выборки\n",
    "process_dataset(train_df, train_dir)\n",
    "process_dataset(test_df, test_dir)\n",
    "\n",
    "print(\"Разделение завершено!\")\n",
    "print(f\"Тренировочных samples: {len(train_df)}\")\n",
    "print(f\"Тестовых samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "366102af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m output_directory = \u001b[33m\"\u001b[39m\u001b[33moutputttttt\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Папка для результатов\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Выполняем разделение\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36msplit_dataset\u001b[39m\u001b[34m(images_dir, csv_file, output_dir, test_size, random_state)\u001b[39m\n\u001b[32m     14\u001b[39m             data.append((row[\u001b[32m0\u001b[39m], row[\u001b[32m1\u001b[39m]))\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Разделение на train и test\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m train_data, test_data = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Создание директорий\u001b[39;00m\n\u001b[32m     20\u001b[39m train_dir = os.path.join(output_dir, \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2848\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mythy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2478\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2481\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2482\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2483\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2485\u001b[39m     )\n\u001b[32m   2487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(images_dir, csv_file, output_dir, test_size=0.2, random_state=42):\n",
    "    # Чтение данных из CSV\n",
    "    data = []\n",
    "    with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:  # Проверяем, что в строке есть хотя бы 2 элемента\n",
    "                data.append((row[0], row[1]))\n",
    "    \n",
    "    # Разделение на train и test\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Создание директорий\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    test_dir = os.path.join(output_dir, 'test')\n",
    "    \n",
    "    os.makedirs(os.path.join(train_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, 'images'), exist_ok=True)\n",
    "    \n",
    "    # Функция для копирования файлов и создания CSV\n",
    "    def process_dataset(data, dataset_dir):\n",
    "        # Копируем изображения\n",
    "        for img_name, label in data:\n",
    "            src_path = os.path.join(images_dir, img_name)\n",
    "            dst_path = os.path.join(dataset_dir, 'images', img_name)\n",
    "            if os.path.exists(src_path):\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        # Создаем CSV файл\n",
    "        csv_path = os.path.join(dataset_dir, 'output.csv')\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for img_name, label in data:\n",
    "                writer.writerow([img_name, label])\n",
    "    \n",
    "    # Обрабатываем train и test наборы\n",
    "    process_dataset(train_data, train_dir)\n",
    "    process_dataset(test_data, test_dir)\n",
    "    \n",
    "    print(f\"Данные разделены:\")\n",
    "    print(f\"  Train: {len(train_data)} записей\")\n",
    "    print(f\"  Test: {len(test_data)} записей\")\n",
    "    print(f\"  Train данные сохранены в: {train_dir}\")\n",
    "    print(f\"  Test данные сохранены в: {test_dir}\")\n",
    "\n",
    "# Использование\n",
    "if __name__ == \"__main__\":\n",
    "    # Укажите пути к вашим данным\n",
    "    images_directory = \"images/\"  # Замените на реальный путь\n",
    "    csv_file_path = \"labels.csv\"  # Замените на реальный путь\n",
    "    output_directory = \"outputttttt\"  # Папка для результатов\n",
    "    \n",
    "    # Выполняем разделение\n",
    "    split_dataset(images_directory, csv_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e3bdec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.jpg,фБөbXҐДЌLKОp|Nt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg,TЊ5ЃF@ӯх{Г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg,_%BЌc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg,;ЕвvУеџ/й,Zџё&gt;5Ш</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg,gљYс3I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.jpg,фБөbXҐДЌLKОp|Nt\n",
       "0        1.jpg,TЊ5ЃF@ӯх{Г\n",
       "1             2.jpg,_%BЌc\n",
       "2  3.jpg,;ЕвvУеџ/й,Zџё>5Ш\n",
       "3            4.jpg,gљYс3I"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels.csv\")\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7e34e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"train.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86939be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>5Hвkг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>ӢWвйДfsЯћ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>?;ГoJю'/ФЩЁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>}n&amp;0oZаҚКZUBрѓ}cEnмS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Ш)ҚLЯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7995.jpg</td>\n",
       "      <td>эGv9mD@Қfша:т</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7996.jpg</td>\n",
       "      <td>ЖЁШiМ|љЋV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7997.jpg</td>\n",
       "      <td>KйQЈ5пчirGLќyмйяЮ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7998.jpg</td>\n",
       "      <td>4*кРїG&amp;Ша|оҳы+ђ&gt;Ш</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>7999.jpg</td>\n",
       "      <td>э9ёvЧTШЩщаNБТК</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     filenames                 words\n",
       "0        0.jpg                 5Hвkг\n",
       "1        1.jpg             ӢWвйДfsЯћ\n",
       "2        2.jpg           ?;ГoJю'/ФЩЁ\n",
       "3        3.jpg  }n&0oZаҚКZUBрѓ}cEnмS\n",
       "4        4.jpg                 Ш)ҚLЯ\n",
       "...        ...                   ...\n",
       "7995  7995.jpg         эGv9mD@Қfша:т\n",
       "7996  7996.jpg             ЖЁШiМ|љЋV\n",
       "7997  7997.jpg    KйQЈ5пчirGLќyмйяЮ€\n",
       "7998  7998.jpg     4*кРїG&Ша|оҳы+ђ>Ш\n",
       "7999  7999.jpg        э9ёvЧTШЩщаNБТК\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2faffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\", sep=',')\n",
    "test = pd.read_csv(\"test.csv\", sep=',')\n",
    "train = train.rename(columns={'filenames': 'filename'})\n",
    "test = test.rename(columns={'filenames': 'filename'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf76dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', sep=',', index=False)\n",
    "test.to_csv('test.csv', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a80dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000.jpg</td>\n",
       "      <td>sJwнТЌk)ў(ӏ;f_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001.jpg</td>\n",
       "      <td>жX[мъaгМccлёЋaqіДҶU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002.jpg</td>\n",
       "      <td>rЈmјЌaщd№</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003.jpg</td>\n",
       "      <td>іаїH@%Uу|қЊ&gt;ПO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004.jpg</td>\n",
       "      <td>Lr}EmөNj*ъ|Ы5UўЏPa!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>9995.jpg</td>\n",
       "      <td>tӨВжя.З0ёМUkѓаӏjНdӢ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>9996.jpg</td>\n",
       "      <td>ғ}c1$Дѓ#ўC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>9997.jpg</td>\n",
       "      <td>qЕ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>9998.jpg</td>\n",
       "      <td>k_Ё</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>9999.jpg</td>\n",
       "      <td>zў{дubgрЮ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                 words\n",
       "0     8000.jpg        sJwнТЌk)ў(ӏ;f_\n",
       "1     8001.jpg   жX[мъaгМccлёЋaqіДҶU\n",
       "2     8002.jpg             rЈmјЌaщd№\n",
       "3     8003.jpg        іаїH@%Uу|қЊ>ПO\n",
       "4     8004.jpg   Lr}EmөNj*ъ|Ы5UўЏPa!\n",
       "...        ...                   ...\n",
       "1995  9995.jpg   tӨВжя.З0ёМUkѓаӏjНdӢ\n",
       "1996  9996.jpg            ғ}c1$Дѓ#ўC\n",
       "1997  9997.jpg                    qЕ\n",
       "1998  9998.jpg                   k_Ё\n",
       "1999  9999.jpg             zў{дubgрЮ\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\", sep=',')\n",
    "test = pd.read_csv(\"test.csv\", sep=',')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd536f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af43bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:80]\n",
    "df.to_csv(\"trainsmall.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895e8917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>5Hвkг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>ӢWвйДfsЯћ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>?;ГoJю'/ФЩЁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>}n&amp;0oZаҚКZUBрѓ}cEnмS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Ш)ҚLЯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75.jpg</td>\n",
       "      <td>Хpғ%ЏsжЯќ`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76.jpg</td>\n",
       "      <td>gЉЦVү#ӣЉ:қGоaДҷ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77.jpg</td>\n",
       "      <td>ЎИbҶяWfC`_Ў</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78.jpg</td>\n",
       "      <td>оґБ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79.jpg</td>\n",
       "      <td>t2Ӯ~&lt;кІ_sщіv+NлКtч</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename                 words\n",
       "0     0.jpg                 5Hвkг\n",
       "1     1.jpg             ӢWвйДfsЯћ\n",
       "2     2.jpg           ?;ГoJю'/ФЩЁ\n",
       "3     3.jpg  }n&0oZаҚКZUBрѓ}cEnмS\n",
       "4     4.jpg                 Ш)ҚLЯ\n",
       "..      ...                   ...\n",
       "75   75.jpg            Хpғ%ЏsжЯќ`\n",
       "76   76.jpg       gЉЦVү#ӣЉ:қGоaДҷ\n",
       "77   77.jpg           ЎИbҶяWfC`_Ў\n",
       "78   78.jpg                   оґБ\n",
       "79   79.jpg    t2Ӯ~<кІ_sщіv+NлКtч\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50f616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test.csv\", sep=',')\n",
    "df = df.iloc[80:100]\n",
    "df.to_csv(\"testsmall.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089c62f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8080.jpg</td>\n",
       "      <td>Itњ9бВ№zҶр`Nnq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8081.jpg</td>\n",
       "      <td>@tҷjвЗX(ыөЕ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8082.jpg</td>\n",
       "      <td>OиІNљdю</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8083.jpg</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8084.jpg</td>\n",
       "      <td>ВғШӣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8085.jpg</td>\n",
       "      <td>]ЌZҚ'Кщрө</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8086.jpg</td>\n",
       "      <td>`ё)уЕуҐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8087.jpg</td>\n",
       "      <td>;КdиӀHmҚ]яYа&lt;ы@w+М</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8088.jpg</td>\n",
       "      <td>Щ0ҷ1l0ЬСа}Ж</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8089.jpg</td>\n",
       "      <td>Р</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>8090.jpg</td>\n",
       "      <td>љky7ӢvхХЬcтУкЃ~'yKЮ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>8091.jpg</td>\n",
       "      <td>юhяү!]Ръӯћґд+њ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8092.jpg</td>\n",
       "      <td>YКЌү;лп</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>8093.jpg</td>\n",
       "      <td>jөЧ7уи%Р]44/oD6Gӣbь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>8094.jpg</td>\n",
       "      <td>'ЯЃШє&lt;Юd?Иkh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8095.jpg</td>\n",
       "      <td>ж'€ЛЬєҚщЇҷвФӀ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8096.jpg</td>\n",
       "      <td>Өп|ЋFґЏoсiпТөe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>8097.jpg</td>\n",
       "      <td>lqіФтbп€p}t!ё</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8098.jpg</td>\n",
       "      <td>ЛpJЎХMUТуї</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8099.jpg</td>\n",
       "      <td>эь.Ђ0іCОёҳ%фKҒІЊИA4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                words\n",
       "80  8080.jpg       Itњ9бВ№zҶр`Nnq\n",
       "81  8081.jpg          @tҷjвЗX(ыөЕ\n",
       "82  8082.jpg              OиІNљdю\n",
       "83  8083.jpg                    e\n",
       "84  8084.jpg                 ВғШӣ\n",
       "85  8085.jpg            ]ЌZҚ'Кщрө\n",
       "86  8086.jpg              `ё)уЕуҐ\n",
       "87  8087.jpg   ;КdиӀHmҚ]яYа<ы@w+М\n",
       "88  8088.jpg          Щ0ҷ1l0ЬСа}Ж\n",
       "89  8089.jpg                    Р\n",
       "90  8090.jpg  љky7ӢvхХЬcтУкЃ~'yKЮ\n",
       "91  8091.jpg       юhяү!]Ръӯћґд+њ\n",
       "92  8092.jpg              YКЌү;лп\n",
       "93  8093.jpg  jөЧ7уи%Р]44/oD6Gӣbь\n",
       "94  8094.jpg         'ЯЃШє<Юd?Иkh\n",
       "95  8095.jpg        ж'€ЛЬєҚщЇҷвФӀ\n",
       "96  8096.jpg       Өп|ЋFґЏoсiпТөe\n",
       "97  8097.jpg        lqіФтbп€p}t!ё\n",
       "98  8098.jpg           ЛpJЎХMUТуї\n",
       "99  8099.jpg  эь.Ђ0іCОёҳ%фKҒІЊИA4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
